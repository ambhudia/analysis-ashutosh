19 Feb 2019

    Replicate Shihan's run using files from nextcloud
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    Purpose: To determine of the model was chnaged since the intial run

        Download files from Nextcloud, upload to cedar
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
            Create directory (/home/abhudia/project/abhudia/MIDOSS/MIDOSS-MOHID-config/ashu_testing/nextcloud_replicate)
            Write .yaml file pointing to all relevant input files
            Edit file paths in Atmosphere.dat, Hydrodynamic.dat

        Compile Mohid
        ^^^^^^^^^^^^^
            salloc --time=0:10:0 --cpus-per-task=1 --mem-per-cpu=1024m --account=def-allen
            cd $PROJECT/$USER/MIDOSS/MIDOSS-MOHID/Solutions/linux
            ./compile_mohid.sh -mb1 -mb2 -mw

            Delete all of the compiled objects, libraries, and executables:
            ./compile_mohid --clean
            so that next build is clean
        
        Run Mohid
        ^^^^^^^^^
            make run directory as set in yaml file ($SCRATCH/MIDOSS/runs/ashu_testing/)
            cd /home/abhudia/project/abhudia/MIDOSS/MIDOSS-MOHID-config/ashu_testing/nextcloud_replicate
            mohid run nextcloud_replicate.yaml $PROJECT/$USER/MIDOSS/results/ashu/nextcloud_replicate

        Outcome
        ^^^^^^^
            crashed with multiple error messages. will investigate.

20 Feb 2019

    Continue developing scripts to generate hdf5 input files for MOHID
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    
        Added w ocean velocity to input file generator function
        !! need to add date validation on input
        !! need to create local file for lat lon data for HRDPS and WW3 grids
    
    Replicate Shihan's run using files from nextcloud
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    Purpose: To determine of the model was chnaged since the intial run

        Download files from Nextcloud, upload to cedar
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
            Create directory (/home/abhudia/project/abhudia/MIDOSS/MIDOSS-MOHID-config/ashu_testing/nextcloud_replicate)
            Write .yaml file pointing to all relevant input files
            Edit file paths in Atmosphere.dat, Hydrodynamic.dat

        Compile Mohid
        ^^^^^^^^^^^^^
            salloc --time=0:10:0 --cpus-per-task=1 --mem-per-cpu=1024m --account=def-allen
            cd $PROJECT/$USER/MIDOSS/MIDOSS-MOHID/Solutions/linux
            ./compile_mohid.sh -mb1 -mb2 -mw

            Delete all of the compiled objects, libraries, and executables:
            ./compile_mohid --clean
            so that next build is clean
        
        Run Mohid
        ^^^^^^^^^
            make run directory as set in yaml file ($SCRATCH/MIDOSS/runs/ashu_testing/)
            cd /home/abhudia/project/abhudia/MIDOSS/MIDOSS-MOHID-config/ashu_testing/nextcloud_replicate
            mohid run nextcloud_replicate.yaml $PROJECT/$USER/MIDOSS/results/ashu/nextcloud_replicate
            Job ID: 17103921
        
        Outcome
        ^^^^^^^
            crashed again. stderr output:
                ReadInitialImposedSolution  - ModuleHydrodynamic - ERR170
                Usage: hdf5-to-netcdf4 [OPTIONS] HDF5_FILE NETCDF4_FILE
                Try "hdf5-to-netcdf4 --help" for help.

                Error: Invalid value for "HDF5_FILE": Path "/scratch/abhudia/MIDOSS/runs/ashu_testing/nextcloud_replicate_2019-02-20T171143.680870-0800/res/Lagrangian_nextcloud_replicate.hdf5" does not exist.


21 Feb 2019

    Continue developing script to generate hdf5 input files for MOHID
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    
        added salinity and temperature
        refactored script to generate file paths and produce hdf5 files in separate functions. added additional validation.
