{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook provides a recipe for creating netcdf files of profiles by looping through the files on in /results2, /results, /opp\n",
    "- It has been heavily generalised to provide a general recipe for making the profiles, rather than providing explicit functions that do the job.\n",
    "- I would estimate that it would take about an hour to concatenate a year's worth of data. Consider a multiprocessing.py approach to creating multiple profiles on a queue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from dateutil.parser import parse\n",
    "# import the file path location from the forcing_paths.py script\n",
    "import importlib.util\n",
    "spec = importlib.util.spec_from_file_location(\"forcing_paths.py\", \"/ocean/abhudia/MEOPAR/analysis-ashutosh/scripts/make-hdf5/forcing_paths.py\")\n",
    "paths = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(paths)\n",
    "\n",
    "# produce profiles using a multiprocessing queue\n",
    "\n",
    "import time\n",
    "import multiprocessing\n",
    "\n",
    "def timer(func):\n",
    "    \"\"\"Decorator function for timing function calls\n",
    "    \"\"\"\n",
    "    def f(*args, **kwargs):\n",
    "        beganat = time.time()\n",
    "        rv = func(*args, *kwargs)\n",
    "        elapsed = time.time() - beganat\n",
    "        hours = int(elapsed / 3600)\n",
    "        mins = int((elapsed - (hours*3600))/60)\n",
    "        secs = int((elapsed - (hours*3600) - (mins*60)))\n",
    "        print('\\nTime elapsed: {}:{}:{}\\n'.format(hours, mins, secs))\n",
    "        return rv\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a list of the files to loop through using the functions in the forcing_paths.py script\n",
    "\n",
    "#### For the timestart, timeend positional arguments, pass a datetime.datetime object natively or simply use parse\n",
    "\n",
    "#### for SSC profiles, the filetype argument is 'grid_U', 'grid_V', 'grid_W', 'grid_T' for U, W, V T parameters respectively; e.g. for U files, \n",
    "```python\n",
    "paths.salishseacast_paths(timestart = parse('1 Jan 2015'), timeend = parse('3 jan 2015'), path = '/results2/SalishSea/nowcast-green.201806/', filetype = 'grid_U')\n",
    "```\n",
    "#### for WaveWatch files, \n",
    "```python\n",
    "paths.ww3_paths(timestart = parse('1 Jan 2015'), timeend = parse('3 jan 2015'), path = '/opp/wwatch3/nowcast/')\n",
    "```\n",
    "#### for HRDPS files,\n",
    "```python\n",
    "paths.hrdps_paths(timestart = parse('1 Jan 2015'), timeend = parse('3 jan 2015'), path = '/results/forcing/atmospheric/GEM2.5/operational/')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Step through creating time profiles of surface U current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a list of paths to, e.g.' grid_U' files between \"start_time\" and \"end_time\"\n",
    "start_time = '1 june 2015'\n",
    "end_time = '20 june 2015'\n",
    "output_netcdf = 'timeseries_' + '_'.join(start_time.split()) + '_' + '_'.join(end_time.split()) + '.nc'\n",
    "U_paths = paths.salishseacast_paths(parse(start_time), parse(end_time), '/results2/SalishSea/nowcast-green.201806/', 'grid_U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From analysis-ashutosh/climatology_analysis_notebooks/Pick grid points.ipynb, we have the locations of the three points chosen as: ((y,x) order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SB=(np.array([256]), np.array([268]))\n",
    "TP=(np.array([343]), np.array([250]))\n",
    "SoG=(np.array([474]), np.array([252]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through the list of files and create a netcdf file of the profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def make_profile(start_time, end_time, output_netcdf):\n",
    "    U_paths = paths.salishseacast_paths(parse(start_time), parse(end_time), '/results2/SalishSea/nowcast-green.201806/', 'grid_U')\n",
    "    first = True\n",
    "    for file_path in U_paths:\n",
    "        f = xr.open_dataset(file_path).isel(depthu = 0).vozocrtx\n",
    "        sog_now = f.isel(y = 256, x = 268)\n",
    "        if first is True:\n",
    "            sog = sog_now\n",
    "            first = False\n",
    "        else:\n",
    "            sog = xr.concat((sog, sog_now), dim = 'time_counter')\n",
    "    # finally, stitch them together and turn the profile into a netcdf file\n",
    "    current_u = xr.Dataset({'SoG': sog})\n",
    "    current_u.to_netcdf(output_netcdf, format = 'NETCDF4',engine = 'netcdf4')\n",
    "    print(output_netcdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:        (time_counter: 480)\n",
       "Coordinates:\n",
       "    nav_lat        float32 ...\n",
       "    nav_lon        float32 ...\n",
       "    depthu         float32 ...\n",
       "    time_centered  (time_counter) datetime64[ns] ...\n",
       "  * time_counter   (time_counter) datetime64[ns] 2015-06-01T00:30:00 ... 2015-06-20T23:30:00\n",
       "Data variables:\n",
       "    SoG            (time_counter) float32 ..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the netcdf file containing the profile\n",
    "xr.open_dataset(output_netcdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "jan2018.nc\n",
      "\n",
      "Time elapsed: 0:0:26\n",
      "\n",
      "jan2017.nc\n",
      "\n",
      "Time elapsed: 0:0:28\n",
      "\n",
      "jan2016.nc\n",
      "\n",
      "Time elapsed: 0:0:17\n",
      "\n",
      "jan2015.nc\n",
      "\n",
      "Time elapsed: 0:0:17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def manage_queue(remaining, workers, current=[]):\n",
    "    print(len(remaining))\n",
    "    while ((len(current) != 0)  or  (len(remaining) != 0)):\n",
    "        if ((len(current) != workers) and (len(remaining) != 0)):\n",
    "            new_task = remaining.pop()\n",
    "            new_task.start()\n",
    "            current.append(new_task)\n",
    "            continue\n",
    "        for task in current:\n",
    "            if task.is_alive():\n",
    "                continue\n",
    "            else:\n",
    "                try:\n",
    "                    task.join()\n",
    "                    current.remove(task)\n",
    "                except RuntimeError as err:\n",
    "                    if 'cannot join current thread' in err.args[0]:\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise\n",
    "        time.sleep(1)\n",
    "    \n",
    "# num_processes_alive = Number of cores to use in multiproccessing\n",
    "# args is list of arguments used an input target function, which in this case is \"make_profile\".  \n",
    "#    If number of args > num_processes_alive then the job is queued and managed by \"manage_queue\"\n",
    "# multiprocessing.Process feeds the arguments to the function.\n",
    "if __name__ == '__main__':\n",
    "    num_processes_alive = 2\n",
    "    processes= []\n",
    "    args = [('1 jan 2015', '7 jan 2015', 'jan2015.nc') ,('1 jan 2016', '7 jan 2016', 'jan2016.nc'), ('1 jan 2017', '7 jan 2017', 'jan2017.nc'), ('1 jan 2018', '7 jan 2018', 'jan2018.nc')]\n",
    "    for i in args:\n",
    "        p = multiprocessing.Process(target = make_profile, args = i)\n",
    "        processes.append(p)\n",
    "    manage_queue(processes, num_processes_alive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
